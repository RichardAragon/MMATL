import torch
import torch.nn as nn
import torch.optim as optim

# Modality-specific encoders
class TextEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, latent_dim):
        super(TextEncoder, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, latent_dim)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

class ImageEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, latent_dim):
        super(ImageEncoder, self).__init__()
        self.conv1 = nn.Conv2d(input_dim, hidden_dim, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(hidden_dim, latent_dim, kernel_size=3, padding=1)
        
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.conv2(x)
        x = x.view(x.size(0), -1)
        return x

# Discriminator for adversarial alignment
class AlignmentDiscriminator(nn.Module):
    def __init__(self, latent_dim):
        super(AlignmentDiscriminator, self).__init__()
        self.fc1 = nn.Linear(latent_dim, latent_dim // 2)
        self.fc2 = nn.Linear(latent_dim // 2, 1)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        return x

# Transfer learning module
class TransferModule(nn.Module):
    def __init__(self, latent_dim, hidden_dim, output_dim):
        super(TransferModule, self).__init__()
        self.fc1 = nn.Linear(latent_dim * 2, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, x1, x2):
        x = torch.cat((x1, x2), dim=1)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Task-specific model
class TaskModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TaskModel, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Discriminator for adversarial task training
class TaskDiscriminator(nn.Module):
    def __init__(self, input_dim):
        super(TaskDiscriminator, self).__init__()
        self.fc1 = nn.Linear(input_dim, input_dim // 2)
        self.fc2 = nn.Linear(input_dim // 2, 1)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        return x

# MMATL model
class MMATL(nn.Module):
    def __init__(self, text_input_dim, image_input_dim, hidden_dim, latent_dim, output_dim):
        super(MMATL, self).__init__()
        self.text_encoder = TextEncoder(text_input_dim, hidden_dim, latent_dim)
        self.image_encoder = ImageEncoder(image_input_dim, hidden_dim, latent_dim)
        self.alignment_discriminator = AlignmentDiscriminator(latent_dim)
        self.transfer_module = TransferModule(latent_dim, hidden_dim, output_dim)
        self.task_model = TaskModel(output_dim, hidden_dim, 1)
        self.task_discriminator = TaskDiscriminator(1)
        
    def forward(self, text, image):
        text_latent = self.text_encoder(text)
        image_latent = self.image_encoder(image)
        
        # Adversarial alignment
        align_loss_enc = torch.mean(torch.log(self.alignment_discriminator(text_latent)) + 
                                    torch.log(1 - self.alignment_discriminator(image_latent)))
        align_loss_dis = torch.mean(torch.log(1 - self.alignment_discriminator(text_latent)) +
                                    torch.log(self.alignment_discriminator(image_latent)))
        
        # Cross-modal transfer
        task_input = self.transfer_module(text_latent, image_latent)
        
        # Adversarial task training
        task_output = self.task_model(task_input)
        task_loss_model = torch.mean(torch.log(self.task_discriminator(task_output)) +
                                     torch.log(1 - self.task_discriminator(torch.ones_like(task_output))))
        task_loss_dis = torch.mean(torch.log(1 - self.task_discriminator(task_output)) +
                                   torch.log(self.task_discriminator(torch.ones_like(task_output))))
        
        return align_loss_enc, align_loss_dis, task_loss_model, task_loss_dis, task_output

# Training loop
def train(model, dataloader, num_epochs, learning_rate, lambda_align, lambda_task):
    optimizer_enc = optim.Adam(list(model.text_encoder.parameters()) + list(model.image_encoder.parameters()), lr=learning_rate)
    optimizer_align_dis = optim.Adam(model.alignment_discriminator.parameters(), lr=learning_rate)
    optimizer_transfer_task = optim.Adam(list(model.transfer_module.parameters()) + list(model.task_model.parameters()), lr=learning_rate)
    optimizer_task_dis = optim.Adam(model.task_discriminator.parameters(), lr=learning_rate)
    
    for epoch in range(num_epochs):
        for text, image, label in dataloader:
            align_loss_enc, align_loss_dis, task_loss_model, task_loss_dis, task_output = model(text, image)
            
            enc_loss = torch.mean(torch.square(task_output - label)) + lambda_align * align_loss_enc
            align_dis_loss = align_loss_dis
            transfer_task_loss = torch.mean(torch.square(task_output - label)) + lambda_task * task_loss_model
            task_dis_loss = task_loss_dis
            
            optimizer_enc.zero_grad()
            enc_loss.backward(retain_graph=True)
            optimizer_enc.step()
            
            optimizer_align_dis.zero_grad()
            align_dis_loss.backward(retain_graph=True)
            optimizer_align_dis.step()
            
            optimizer_transfer_task.zero_grad()
            transfer_task_loss.backward(retain_graph=True)
            optimizer_transfer_task.step()
            
            optimizer_task_dis.zero_grad()
            task_dis_loss.backward()
            optimizer_task_dis.step()
        
        print(f"Epoch [{epoch+1}/{num_epochs}], Encoder Loss: {enc_loss.item():.4f}, Alignment Discriminator Loss: {align_dis_loss.item():.4f}, Transfer+Task Loss: {transfer_task_loss.item():.4f}, Task Discriminator Loss: {task_dis_loss.item():.4f}")
